{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "179cc221",
   "metadata": {},
   "source": [
    "# Offline Simulation\n",
    "The goal here is to debug why simulated offline decoding performance is worse than validation/test accuracy using EEGNet-2,2. The same data will be used for training and testing EEGNet-2,2 (BM_dataset_movement_1). To determine the discrepency between online decoding and offline I trianing I will do the following:\n",
    "1. I will set up an offline simulation, run it, and visualize the decoder output along with the accuracy at each time instance.\n",
    "2. I will check the results on each test example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbf156c",
   "metadata": {},
   "source": [
    "## BCI Offline Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a746bf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import preprocessing as pre\n",
    "%matplotlib qt\n",
    "\n",
    "from preprocessing import load_data, parse_labels, partition_data, augment_data\n",
    "from train import train\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "import pdb\n",
    "from EEGNet import EEGNet\n",
    "import argparse\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0e08769",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-becb2dad54ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[0mz_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meeg_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'databuffer'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[0mz_std\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meeg_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'databuffer'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[0meeg_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'databuffer'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0meeg_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'databuffer'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mz_mean\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mz_std\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;31m# main loop over time in trial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run the offline simulation\n",
    "'''\n",
    "Simulates real-time decoding of offline EEG data\n",
    "\n",
    "Brandon McMahan\n",
    "October 4, 2021\n",
    "'''\n",
    "import data.data_util as util\n",
    "import numpy as np\n",
    "from offline_modules import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import CenterCrop\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import pdb \n",
    "from preprocessing import bandpass_channels\n",
    "\n",
    "###########################################################################\n",
    "# Module Constructors\n",
    "###########################################################################\n",
    "# EEG Filter constructor\n",
    "zi = None\n",
    "\n",
    "\n",
    "# NEXT NEIGHBORS LAPLACIAN FILTERING\n",
    "electrode_names = ['Fp1', 'Fpz', 'Fp2',\n",
    "          'F7', 'F3', 'Fz', 'F4', 'F8',\n",
    "          'FC5', 'FC1', 'FC2', 'FC6',\n",
    "          'M1', 'T7', 'C3', 'Cz', 'C4', 'T8', 'M2',\n",
    "          'CP5', 'CP1', 'CP2', 'CP6',\n",
    "          'P7', 'P3', 'Pz', 'P4', 'P8', 'POz',\n",
    "          'O1', 'O2', 'EOG',\n",
    "          'AF7', 'AF3', 'AF4', 'AF8',\n",
    "          'F5', 'F1', 'F2', 'F6',\n",
    "          'FC3', 'FCz', 'FC4',\n",
    "          'C5', 'C1', 'C2', 'C6',\n",
    "          'CP3', 'CP4',\n",
    "          'P5', 'P1', 'P2', 'P6',\n",
    "          'PO5', 'PO3', 'PO4', 'PO6',\n",
    "          'FT7', 'FT8', 'TP7', 'TP8',\n",
    "          'PO7', 'PO8', 'Oz']\n",
    "\n",
    "inds_original = np.array([\n",
    "    [0, 4], [0, 5], [0, 6], [2, 1], [2, 3], [2, 5], [2, 7], [2, 9],\n",
    "    [3, 2], [3, 4], [3, 6], [3, 8], [4, 0], [4, 1], [4, 3], [4, 5], [4, 7], [4, 9], [4, 10], \n",
    "    [5, 2], [5, 4], [5, 6], [5, 8], [6, 1], [6, 3], [6, 5], [6, 7], [6, 9],\n",
    "    [7, 5], [8, 4], [8, 6], [0, 0], [1, 1], [1, 3], [1, 7], [1, 9],\n",
    "    [2, 2], [2, 4], [2, 6], [2, 8], [3, 3], [3, 5], [3, 7],\n",
    "    [4, 2], [4, 4], [4, 6], [4, 8], [5, 3], [5, 7],\n",
    "    [6, 2], [6, 4], [6, 6], [6, 8],\n",
    "    [7, 2], [7, 3], [7, 7], [7, 8],\n",
    "    [3, 1], [3, 9], [5, 1], [5, 9], [7, 1], [7, 9], [8, 5]\n",
    "    ])\n",
    "GRIDSHAPE = (11, 9)\n",
    "\n",
    "inds_grid = np.zeros(GRIDSHAPE, dtype='int')*np.nan\n",
    "for i, ind in enumerate(inds_original):\n",
    "    inds_grid[ind[1], ind[0]] = i\n",
    "\n",
    "next_neighbors = [] # if horizontal distance is 2 or vertical distance is 2\n",
    "for i, ind in enumerate(inds_original):\n",
    "    iy, ix = ind\n",
    "\n",
    "    neighbors_i = []\n",
    "    if ix > 1 and ~np.isnan(inds_grid[ix-2, iy]):\n",
    "        neighbors_i.append(int(inds_grid[ix-2, iy]))\n",
    "    if ix < GRIDSHAPE[0]-2 and ~np.isnan(inds_grid[ix+2, iy]):\n",
    "        neighbors_i.append(int(inds_grid[ix+2, iy]))\n",
    "    if iy > 1 and ~np.isnan(inds_grid[ix, iy-2]):\n",
    "        neighbors_i.append(int(inds_grid[ix, iy-2]))\n",
    "    if iy < GRIDSHAPE[1]-2 and ~np.isnan(inds_grid[ix, iy+2]):\n",
    "        neighbors_i.append(int(inds_grid[ix, iy+2]))\n",
    "    next_neighbors.append(neighbors_i)\n",
    "next_adjacency = np.zeros((64, 64))\n",
    "for i, neighbors_i in enumerate(next_neighbors):\n",
    "    next_adjacency[i, neighbors_i] = 1\n",
    "D = 64\n",
    "laplacian_next = np.eye(D) - (next_adjacency/np.maximum(np.sum(next_adjacency, axis=1), 1)).T\n",
    "laplacian_next = torch.FloatTensor(laplacian_next).cuda()  # put on device\n",
    "\n",
    "# load offline-trained EEGNet\n",
    "class SeparableConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, bias=False):\n",
    "        super(SeparableConv2d, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, \n",
    "                                   groups=in_channels, bias=bias, padding=0)\n",
    "        self.pointwise = nn.Conv2d(in_channels, out_channels, \n",
    "                                   kernel_size=(1,1), bias=bias)\n",
    "    def forward(self, x):\n",
    "        out = self.depthwise(x)\n",
    "        out = self.pointwise(out)\n",
    "        return out\n",
    "\n",
    "class ConstrainedDepthwiseConv2d(nn.Conv2d):\n",
    "    def __init__(self, F1, D):\n",
    "        super(ConstrainedDepthwiseConv2d, self).__init__(F1, F1*D, (59, 1), groups=F1)\n",
    "        self._max_norm_val = 1\n",
    "        self._eps = 0.01\n",
    "    def forward(self, input):\n",
    "        return F.conv2d(input, self._max_norm(self.weight), self.bias, self.stride,\n",
    "                        self.padding, self.dilation, self.groups)\n",
    "    def _max_norm(self, w):\n",
    "        norm = w.norm(2, dim=0, keepdim=True)\n",
    "        desired = torch.clamp(norm, 0, self._max_norm_val)\n",
    "        return w * (desired / (self._eps + norm))\n",
    "\n",
    "class ConstrainedDense(nn.Linear):\n",
    "    def __init__(self):\n",
    "        super(ConstrainedDense, self).__init__(4, 2)   # Inputs to dense should be F2\n",
    "        self._max_norm_val = 0.25\n",
    "        self._eps = 0.01\n",
    "    def forward(self, input):\n",
    "        return F.linear(input, self._max_norm(self.weight), self.bias)\n",
    "    def _max_norm(self, w):\n",
    "        norm = w.norm(2, dim=0, keepdim=True)\n",
    "        desired = torch.clamp(norm, 0, self._max_norm_val)\n",
    "        return w * (desired / (self._eps + norm))\n",
    "\n",
    "class EEGNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_length=1, input_dim=63, output_dim=2, F1=2, D=2, F2=4):\n",
    "        super(EEGNet, self).__init__()\n",
    "\n",
    "        self.T = 1000  # timestamps in data\n",
    "        self.C = 59    # electrodes in data\n",
    "\n",
    "        # BLOCK 1 LAYERS\n",
    "        self._input_crop = CenterCrop([59, 1000]).cuda()\n",
    "        \n",
    "        # layer 1\n",
    "        self._conv1 = nn.Conv2d(1, F1, (1, 500), padding=0).cuda()\n",
    "        self._batchnorm1 = nn.BatchNorm2d(F1, False).cuda()\n",
    "\n",
    "        # layer 2\n",
    "        self._depthwise = ConstrainedDepthwiseConv2d(F1, D).cuda()  #nn.Conv2d(F1, F1*D, (59, 1), groups=F1).cuda()\n",
    "        self._batchnorm2 = nn.BatchNorm2d(F1*D).cuda()\n",
    "        self._avg_pool = nn.AvgPool2d((1,31)).cuda()\n",
    "        self._dropout1 = nn.Dropout(p=0.5).cuda()\n",
    "\n",
    "        # seperable convolution\n",
    "        self._seperable = SeparableConv2d(F1*D, F2, (1,16)).cuda()\n",
    "        self._batchnorm3 = nn.BatchNorm2d(F2).cuda()\n",
    "        self._dropout2 = nn.Dropout(p=0.5).cuda()\n",
    "        self._dense = ConstrainedDense().cuda()\n",
    "\n",
    "        #self.input_dim = input_dim\n",
    "        #self.output_dim = output_dim\n",
    "        #if not isinstance(input_length, int):\n",
    "        #    raise ValueError('input_length must be an int')\n",
    "        #self.input_length = input_length\n",
    "        #self.fc_dims = (input_dim*input_length, output_dim)\n",
    "        #self.fc = nn.Linear(*self.fc_dims)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if isinstance(x, np.ndarray):  # cast to PyTorch tensor\n",
    "            x = torch.FloatTensor(x)\n",
    "\n",
    "        # input to model should be (batch_size, 1, electrodes, t_steps)\n",
    "        X = self.reshape_input(x)\n",
    "        \n",
    "        # BLOCK 1\n",
    "        #X = CenterCrop(X)\n",
    "        X = self._conv1(X)\n",
    "        X = self._batchnorm1(X)\n",
    "        X = self._depthwise(X)\n",
    "        X = self._batchnorm2(X)\n",
    "        X = nn.ELU()(X)\n",
    "        X = self._avg_pool(X)\n",
    "        X = self._dropout1(X)\n",
    "\n",
    "        # BLOCK 2\n",
    "        X = self._seperable(X)\n",
    "        #X = self._batchnorm3(X)\n",
    "        X = nn.ELU()(X)\n",
    "        X = self._dropout2(X)\n",
    "        X = torch.flatten(X, start_dim=1)\n",
    "        X = self._dense(X)\n",
    "        X = nn.Softmax()(X)\n",
    "\n",
    "        return X\n",
    "\n",
    "\n",
    "    def reshape_input(self, x):\n",
    "        '''\n",
    "        x will be shape (1000, 64)\n",
    "        Reshapes X to (1, 1, 64, 1000) which is batch_size, input_channels, electrodes, timesteps\n",
    "\n",
    "        at inference the batch size will be 1\n",
    "        the channel dimension is always 1 since EEG is interpreted as a greyscale image\n",
    "        we only take 59 channels \n",
    "        we have a 64 chanel system\n",
    "        and we have 1000 timesteps in a second\n",
    "        '''\n",
    "        x = torch.transpose(x, 0, 1).cuda()   # x is now (64, 100)        # use for online\n",
    "        #pdb.set_trace()\n",
    "        #x = x.permute(0,3,1,2).cuda()              # use for offline\n",
    "        x = self._input_crop(x)      # (59, 1000)\n",
    "        x = torch.unsqueeze(torch.unsqueeze(x, 0), 0) # (1, 1, 59, 1000)   # use for online\n",
    "        return x\n",
    "\n",
    "init_path = \"C:/Users/DNNeu/KaoLab/EEG_Decoding/Offline_EEG_Decoding/trained_models/trained_EEGNet-2,2\"\n",
    "model = EEGNet()\n",
    "model.load_state_dict(torch.load(init_path))\n",
    "\n",
    "# decoder params\n",
    "decoded_x = 0\n",
    "elapsed_cue_steps = 0\n",
    "###########################################################################\n",
    "\n",
    "# load in the offline data\n",
    "fpath = \"data/JN_movement_w_feedback_0\"\n",
    "eeg_data = util.load_data(fpath + \"/eeg.bin\")\n",
    "task_data = util.load_data(fpath + \"/task.bin\")\n",
    "\n",
    "# extract mean\n",
    "eeg_data['databuffer'] = pre.bandpass_channels(eeg_data['databuffer'][:, 0:64])\n",
    "eeg_data['databuffer'] = torch.from_numpy(eeg_data['databuffer']).cuda()\n",
    "eeg_data['databuffer'] = eeg_data['databuffer']@laplacian_next.T\n",
    "#eeg_data['databuffer'] = pre.normalize_channels(eeg_data['databuffer'])\n",
    "z_mean = torch.mean(eeg_data['databuffer'][:,0:64], axis=0)\n",
    "z_std = torch.std(eeg_data['databuffer'][:,0:64], axis=0)\n",
    "assert False\n",
    "eeg_data['databuffer'] = (eeg_data['databuffer']-z_mean) / z_std\n",
    "# main loop over time in trial\n",
    "# set the starting time\n",
    "# increment the starting time by 20ms at every step\n",
    "\n",
    "# load in different data to run in online decoder\n",
    "fpath = \"data/BM_movement_feedback_1\"\n",
    "eeg_data = util.load_data(fpath + \"/eeg.bin\")\n",
    "task_data = util.load_data(fpath + \"/task.bin\")\n",
    "\n",
    "start_time = np.min(eeg_data[\"time_ns\"])  # time of first EEG sample in nanoseconds\n",
    "end_time = np.max(eeg_data[\"time_ns\"])  # time of last EEG sample in nanoseconds\n",
    "\n",
    "sim_time = start_time + 20000000 # 20 ms timestep\n",
    "\n",
    "'''\n",
    "Simulator output has 4 arrays\n",
    "time (ms)\n",
    "state of task\n",
    "decoded P(left)\n",
    "decoded P(right)\n",
    "decoded x-position\n",
    "'''\n",
    "# generate simulation time steps\n",
    "sim_times = []\n",
    "while (sim_time < end_time):\n",
    "    sim_times.append(sim_time)\n",
    "    sim_time+=20000000\n",
    "\n",
    "simulator_output = np.zeros((5, len(sim_times) + 1))\n",
    "ix = 0\n",
    "old_eeg_ix = 0\n",
    "eeg_buffer_signal = np.zeros_like(eeg_data[\"eegbuffersignal\"])\n",
    "\n",
    "\n",
    "offline_model = EEGNet(F1=2, D=2)  #torch.load(\"trained_models/\" + args.EEGNet_name + \".pt\")\n",
    "offline_model.load_state_dict(torch.load(\"trained_models/trained_EEGNet-2,2\"))\n",
    "offline_model.eval()\n",
    "\n",
    "for sim_time in tqdm.tqdm(sim_times):  \n",
    "    # compute the eeg and task indices\n",
    "    curr_eeg_ix = np.where(eeg_data[\"time_ns\"] > sim_time)[0][0]\n",
    "    curr_task_ix = np.where(task_data[\"time_ns\"] > sim_time)[0][0]\n",
    "\n",
    "    # update the eeg and task buffers\n",
    "    new_eeg_data = eeg_data[\"eegbuffersignal\"][old_eeg_ix:curr_eeg_ix, :]  # (n_t_steps, n_electrodes)\n",
    "    state_task_buffer = task_data[\"state_task\"][:curr_task_ix]      # (n_t_steps',)       NOTE: n_t_steps' != n_t_steps\n",
    "\n",
    "    if curr_eeg_ix > old_eeg_ix:  # if we have new eeg data\n",
    "        # filter EEG data\n",
    "        #eeg_buffer_signal[old_eeg_ix:curr_eeg_ix,:]\n",
    "        new_eeg_data, zi = filterEEG(new_eeg_data, zi)  # filter\n",
    "        new_eeg_data = new_eeg_data[:, 0:64]@laplacian_next.T.cpu().numpy() # spatial filter\n",
    "        new_eeg_data = new_eeg_data - z_mean.cpu().numpy()\n",
    "        new_eeg_data = new_eeg_data / z_std.cpu().numpy()\n",
    "        eeg_buffer_signal[old_eeg_ix:curr_eeg_ix,0:64] = new_eeg_data\n",
    "\n",
    "        # apply online decoder\n",
    "        start_ix = np.maximum(0, curr_eeg_ix - 1000)\n",
    "        decoder_pred = decode(eeg_buffer_signal[start_ix:curr_eeg_ix,:], model, laplacian_next, mean=z_mean, std=z_std)\n",
    "        decoder_pred = offline_model(eeg_buffer_signal[start_ix:curr_eeg_ix, 0:64])[0]#decode(eeg_buffer_signal[-1000:curr_eeg_ix,:], model, laplacian_next, mean=z_mean, std=z_std)  # previously used eeg_data_buffer\n",
    "        #print(\"decoder output:\", decoder_pred)\n",
    "        #print(\"decoder input:\", eeg_buffer_signal[start_ix:curr_eeg_ix, 0:64].shape)\n",
    "        #print(\"new eeg data:\", new_eeg_data.shape)\n",
    "        #print(\"curr eeg ix:\", curr_eeg_ix)\n",
    "        #print(\"start ix:\", start_ix)\n",
    "        # decoder_pred is (2,)\n",
    "        # specifically is (p(left), p(right))\n",
    "\n",
    "    # compute decoded position\n",
    "    if state_task_buffer[-1] == 4:  # reset decoded position\n",
    "        decoded_x = 0\n",
    "        elapsed_cue_steps = 0  # only show the decoder after cue has been presented for 1 second\n",
    "    else:\n",
    "        elapsed_cue_steps += 1  # number of elapsed 20ms bins\n",
    "\n",
    "    if elapsed_cue_steps > 50:  # only draw decoder if \n",
    "        if (decoder_pred[1] - decoder_pred[0]) > 0.6:\n",
    "            decoded_x += 0.1\n",
    "        elif (decoder_pred[1] - decoder_pred[0]) < -0.6:\n",
    "            decoded_x += -0.1\n",
    "\n",
    "\n",
    "    # increment the simulation and store outputs\n",
    "    simulator_output[0, ix] = (sim_time-start_time)/1000000000  # elapsed time in ms\n",
    "    simulator_output[1, ix] = state_task_buffer[-1]         # current task state\n",
    "    simulator_output[2, ix] = decoder_pred[0].item()                # current P(left)\n",
    "    simulator_output[3, ix] = decoder_pred[1].item()                # current P(right)\n",
    "    simulator_output[4, ix] = decoded_x                      # curr decoded x-pos\n",
    "    sim_time += 20000000\n",
    "    old_eeg_ix = curr_eeg_ix\n",
    "    ix += 1\n",
    "    \n",
    "    #if ix == 5000:\n",
    "    #    break\n",
    "\n",
    "simulator_output = simulator_output[:,:ix]\n",
    "    \n",
    "plt.plot(simulator_output[0], simulator_output[1])\n",
    "plt.plot(simulator_output[0], simulator_output[2])\n",
    "plt.plot(simulator_output[0], simulator_output[3])\n",
    "plt.plot(simulator_output[0], simulator_output[4])\n",
    "\n",
    "plt.legend([\"Task State\", \"P(left)\", \"P(right)\", \"Decoded X-pos\"])\n",
    "plt.xlabel(\"Time (sec)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e20d974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.1324e-06, 5.4769e-06, 3.9288e-06, 3.1113e-06, 2.1336e-06, 2.4442e-06,\n",
       "        2.0655e-06, 2.3654e-06, 2.8693e-06, 2.5689e-06, 2.7688e-06, 2.6323e-06,\n",
       "        5.8965e-06, 2.8218e-06, 1.7987e-06, 2.5700e-06, 2.1210e-06, 2.8341e-06,\n",
       "        5.1364e-06, 2.5651e-06, 2.0611e-06, 2.2744e-06, 1.9638e-06, 3.4307e-06,\n",
       "        2.1851e-06, 2.4798e-06, 2.1549e-06, 3.9766e-06, 3.5549e-06, 4.0597e-06,\n",
       "        3.4266e-06, 7.7383e-06, 4.6822e-06, 2.7141e-06, 2.3666e-06, 2.9095e-06,\n",
       "        2.0596e-06, 2.0538e-06, 2.7327e-06, 2.0009e-06, 2.2115e-06, 2.4880e-06,\n",
       "        1.9676e-06, 2.4736e-06, 2.0292e-06, 1.9860e-06, 2.2351e-06, 2.7554e-06,\n",
       "        3.3872e-06, 3.0229e-06, 2.0519e-06, 2.2880e-06, 3.5816e-06, 4.3070e-06,\n",
       "        2.1886e-06, 3.1697e-06, 4.4126e-06, 2.8868e-06, 2.4908e-06, 3.5868e-06,\n",
       "        3.3369e-06, 2.5924e-06, 2.1432e-06, 5.2947e-06], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b9236379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laplacian_next.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c1be1b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Simulation (preprocessed and normalized)')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(10)\n",
    "plt.plot(eeg_buffer_signal[:10000, 0:64])\n",
    "plt.title(\"Simulation\")\n",
    "\n",
    "plt.figure(11)\n",
    "plt.plot(np.transpose(data[0,:,:,0]))\n",
    "plt.title(\"Offline (first trial)\")\n",
    "\n",
    "plt.figure(13)\n",
    "#std = z_std.cpu().numpy()\n",
    "#mean = z_mean.cpu().numpy()\n",
    "plt.plot(eeg_data['databuffer'][:10000].cpu().numpy())\n",
    "plt.title(\"Simulation (preprocessed and normalized)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "28a2d973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1614354cdd8>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(14)\n",
    "plt.plot(task_data['state_task'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9be45b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = 2000\n",
    "task_data['eeg_step'][ix] - task_data['eeg_step'][ix-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "147f614e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.2692682e-05, -2.1029911e-05, -2.2159278e-05, ...,\n",
       "         2.6499608e-06,  1.2717295e-06,  1.9897991e-06],\n",
       "       [-2.4552886e-05, -2.1959777e-05, -2.3877456e-05, ...,\n",
       "         4.8732255e-07, -5.5713110e-07, -3.1274652e-08],\n",
       "       [-2.6303125e-05, -2.2803690e-05, -2.5493397e-05, ...,\n",
       "        -1.5304253e-06, -2.2715524e-06, -1.9310544e-06],\n",
       "       ...,\n",
       "       [ 5.3904969e-06, -3.1097397e-06, -5.0927378e-07, ...,\n",
       "        -1.1933269e-06,  3.5347346e-06,  4.6029905e-07],\n",
       "       [ 4.4996214e-06, -3.9818460e-06, -9.5137818e-07, ...,\n",
       "        -1.3129273e-06,  3.5288797e-06,  3.7496307e-07],\n",
       "       [ 3.4515731e-06, -4.8494408e-06, -1.4338192e-06, ...,\n",
       "        -1.4117735e-06,  3.5265580e-06,  3.2282054e-07]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg_data['databuffer'][:2853, 0:64] - mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "062ca7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.4628e-11,  4.2082e-10,  2.4777e-10,  7.5516e-11,  5.3662e-11,\n",
       "       -1.6719e-11,  1.4088e-11,  2.3044e-10, -9.5130e-11,  8.8514e-11,\n",
       "       -1.0393e-11,  1.4649e-10,  1.7038e-10,  2.0938e-11, -5.5727e-11,\n",
       "       -1.4202e-10,  3.1218e-11, -1.0551e-10, -3.0852e-11,  1.2233e-11,\n",
       "       -2.7044e-11, -5.3061e-11, -3.0882e-11, -1.0780e-10,  4.7582e-11,\n",
       "        9.6878e-11, -1.1857e-10, -2.0966e-11, -2.2053e-12,  1.9628e-11,\n",
       "       -9.4556e-11,  7.9081e-10,  4.5097e-12,  1.9936e-10,  7.1391e-11,\n",
       "        1.9369e-10,  1.4240e-10,  5.2596e-11, -9.0557e-11,  1.5168e-10,\n",
       "       -1.1751e-10, -1.3228e-11, -6.1219e-11, -1.7424e-10, -9.9240e-11,\n",
       "       -6.3743e-12, -3.0172e-11, -9.3875e-11,  2.6118e-11,  9.6182e-11,\n",
       "        1.5962e-11,  2.6794e-11, -7.7036e-11,  8.6030e-12,  4.5420e-11,\n",
       "       -6.6470e-11, -4.9431e-11,  1.1470e-10, -3.5395e-12,  7.3352e-12,\n",
       "       -4.6200e-11, -5.9201e-11, -1.2082e-11, -1.6625e-10])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fabe9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = simulator_output[0]\n",
    "sim_task_state = simulator_output[1]\n",
    "p_left = simulator_output[2]\n",
    "p_right = simulator_output[3]\n",
    "simulated_x = simulator_output[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ad0265d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f57c312ef0>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(time[sim_task_state!=4], p_right[sim_task_state!=4])\n",
    "plt.plot(time[sim_task_state!=4], sim_task_state[sim_task_state!=4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d77894e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f5202fbdd8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(2)\n",
    "plt.plot(time[sim_task_state!=4], np.clip(simulated_x[sim_task_state!=4]+0.5, 0, 1))\n",
    "plt.plot(time[sim_task_state!=4], sim_task_state[sim_task_state!=4])\n",
    "plt.legend([\"Decoded X\", \"True Target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b6884852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15082\n",
      "Percentage of time target is acquired: 0.6941387083941122\n",
      "Percentage of time decoder is close to target: 0.7396896963267471\n"
     ]
    }
   ],
   "source": [
    "n_decoder_output = np.sum(np.clip(simulated_x[sim_task_state!=4]+0.5, 0, 1) != 0.5)\n",
    "print(n_decoder_output)\n",
    "accuracy_strict = np.sum(np.clip(simulated_x[sim_task_state!=4]+0.5, 0, 1) == sim_task_state[sim_task_state!=4])/n_decoder_output\n",
    "print(\"Percentage of time target is acquired:\", accuracy_strict)\n",
    "\n",
    "accuracy_lenient = np.clip(simulated_x[sim_task_state!=4]+0.5, 0, 1) - sim_task_state[sim_task_state!=4]\n",
    "accuracy_lenient = np.abs(accuracy_lenient)\n",
    "accuracy_lenient = np.sum(accuracy_lenient < 0.5) / n_decoder_output\n",
    "print(\"Percentage of time decoder is close to target:\", accuracy_lenient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09850c30",
   "metadata": {},
   "source": [
    "## Discrepancy between online and offline EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a1ff2f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applying laplacian\n"
     ]
    }
   ],
   "source": [
    "# load in the data\n",
    "fpath = \"data/BM_movement_1\"\n",
    "eeg_data = util.load_data(fpath + \"/eeg.bin\")\n",
    "task_data = util.load_data(fpath + \"/task.bin\")\n",
    "\n",
    "# bandpass the data\n",
    "eeg_data['databuffer'] = eeg_data['databuffer'][:, 0:64]\n",
    "eeg_data['databuffer'] = pre.bandpass_channels(eeg_data['databuffer'])\n",
    "eeg_data['databuffer'] = pre.next_next_neighbors_filter(eeg_data['databuffer'])\n",
    "eeg_data['databuffer'] = pre.normalize_channels(eeg_data['databuffer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8a2bb06a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Manually loading data')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(11)\n",
    "plt.plot(np.transpose(data[0,:,:,0]))\n",
    "plt.title(\"Offline (first trial)\")\n",
    "\n",
    "plt.figure(13)\n",
    "#std = z_std.cpu().numpy()\n",
    "#mean = z_mean.cpu().numpy()\n",
    "plt.plot(eeg_data['databuffer'][:10000])\n",
    "plt.title(\"Manually loading data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbc5f86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f473108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dcf91f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97477e82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757689b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d618aed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e41ef2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2e74d10",
   "metadata": {},
   "source": [
    "## EEGNet-2,2 Offline Evaluation\n",
    "First look at accuracy of EEGNet-2,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4302d635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate EEGNet-2,2\n",
    "from preprocessing import load_data, parse_labels, partition_data, augment_data\n",
    "from train import train\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "import pdb\n",
    "from EEGNet import EEGNet\n",
    "import argparse\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "083d592f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applying laplacian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 206/206 [00:00<00:00, 206556.69it/s]\n",
      "Augmenting data: 100%|█████████████████████████████████████████████████████████████| 206/206 [00:00<00:00, 1454.59it/s]\n",
      "  0%|                                                                                           | 0/31 [00:00<?, ?it/s]C:\\Users\\DNNeu\\kaolab\\eeg_decoding\\offline_eeg_decoding\\EEGNet.py:109: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  X = nn.Softmax()(X)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:01<00:00, 26.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy (%): 86.07562255859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data, labels = load_data([\"BM_movement_1\"], filter=True, normalize=True)  # BM_movement_2 held out for testing\n",
    "data, labels = parse_labels(data, labels)\n",
    "train_ds, val_ds, test_ds = partition_data(data, labels, splits=[0.0, 0.0, 1.0])\n",
    "test_ds = augment_data(test_ds)\n",
    "\n",
    "test_dataset = TensorDataset(torch.from_numpy(test_ds[0]).type(torch.float), torch.from_numpy(test_ds[1]).type(torch.long))\n",
    "test_dataset = DataLoader(test_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "EEGNet_model = EEGNet(F1=2, D=2)  #torch.load(\"trained_models/\" + args.EEGNet_name + \".pt\")\n",
    "EEGNet_model.load_state_dict(torch.load(\"trained_models/trained_EEGNet-2,2\"))\n",
    "EEGNet_model.eval()\n",
    "num_correct = 0\n",
    "num_samples = 0\n",
    "for i, (inputs, labels) in enumerate(tqdm.tqdm(test_dataset)):\n",
    "    labels = labels.cuda()\n",
    "    # forward + backward + optimize\n",
    "    outputs = EEGNet_model(inputs)\n",
    "    # get training accuracy\n",
    "    softmax_vals, softmax_indices = outputs.max(1)\n",
    "    num_correct += (softmax_indices == labels).sum()\n",
    "    num_samples += softmax_indices.size(0)\n",
    "accuracy = 100*num_correct / num_samples\n",
    "print(\"Test set accuracy (%):\", accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7818637e",
   "metadata": {},
   "source": [
    "Next, look at the accuracy of EEGNet-2,2 on a trial by trial basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5ec7465e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applying laplacian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 206/206 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data, labels = load_data([\"BM_movement_1\"], filter=True, normalize=True)  # BM_movement_2 held out for testing\n",
    "task_state = np.ones((data.shape[0], data.shape[2]-2000))\n",
    "for trial_ix in range(data.shape[0]):\n",
    "    if labels[trial_ix] == \"left\":\n",
    "        task_state[trial_ix, :] = 0\n",
    "    else:\n",
    "        task_state[trial_ix, :] = 1\n",
    "task_state.reshape(-1).shape\n",
    "plt.plot(task_state.reshape(-1))\n",
    "data, labels = parse_labels(data, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dfa07c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1601c5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25b86bd5ef0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_state = np.ones((data.shape[0], data.shape[2]-2000))\n",
    "for trial_ix in range(data.shape[0]):\n",
    "    task_state[trial_ix, :] = labels[trial_ix]\n",
    "task_state.reshape(-1).shape\n",
    "plt.plot(task_state.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d0b47f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(torch.from_numpy(data).type(torch.float), torch.from_numpy(labels).type(torch.long))\n",
    "test_dataset = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d44a8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/102 [00:00<?, ?it/s]C:\\Users\\DNNeu\\KaoLab\\EEG_Decoding\\Offline_EEG_Decoding\\EEGNet.py:109: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  X = nn.Softmax()(X)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 102/102 [04:33<00:00,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy (%): 72.23174285888672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EEGNet_model = EEGNet(F1=2, D=2)  #torch.load(\"trained_models/\" + args.EEGNet_name + \".pt\")\n",
    "EEGNet_model.load_state_dict(torch.load(\"trained_models/trained_EEGNet-2,2\"))\n",
    "EEGNet_preds = np.zeros((data.shape[0], data.shape[2]-2000))\n",
    "EEGNet_probs = np.zeros((data.shape[0], data.shape[2]-2000, 2))\n",
    "trial_ix = 0\n",
    "EEGNet_model.eval()\n",
    "num_correct = 0\n",
    "num_samples = 0\n",
    "for i, (inputs, labels) in enumerate(tqdm.tqdm(test_dataset)):\n",
    "    counter = 0\n",
    "    labels = labels.cuda()\n",
    "    # forward + backward + optimize\n",
    "    for counter in range(data.shape[2]-2000):\n",
    "        outputs = EEGNet_model(inputs[:,:,1000+counter:counter+2000,:])\n",
    "        # get training accuracy\n",
    "        softmax_vals, softmax_indices = outputs.max(1)\n",
    "        EEGNet_probs[trial_ix, counter] = outputs.detach().cpu().numpy()\n",
    "        num_correct += (softmax_indices == labels).sum()\n",
    "        num_samples += softmax_indices.size(0)\n",
    "        EEGNet_preds[trial_ix, counter] = softmax_indices.item()\n",
    "    trial_ix += 1\n",
    "accuracy = 100*num_correct / num_samples\n",
    "print(\"Test set accuracy (%):\", accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e63e9bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 1854)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EEGNet_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7d7fb477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 2854)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "03b3baab",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'shhape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-118-18021421c7b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtask_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshhape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'shhape'"
     ]
    }
   ],
   "source": [
    "task_state.shhape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "75ddeb22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 2854)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EEGNet_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2dcc48f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 1., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 1., 0., 0.]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EEGNet_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4c8200b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a39e8cdf60>]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ix = 9\n",
    "plt.plot(EEGNet_preds[ix])\n",
    "plt.plot(task_state[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e7e366ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 2854)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5c06522a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'EEGNet Predicted Outputs')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(EEGNet_preds.reshape(-1))\n",
    "plt.plot(task_state.reshape(-1))\n",
    "plt.legend(['EEGNet Prediction', 'Task State (ground truth)'])\n",
    "plt.title(\"EEGNet Predicted Outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7d310d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy (%): 71.91489069348833\n"
     ]
    }
   ],
   "source": [
    "correct = np.sum(EEGNet_preds.reshape(-1) == task_state.reshape(-1))\n",
    "total = len(EEGNet_preds.reshape(-1))\n",
    "print(\"accuracy (%):\", 100 * correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "baccecaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 2854)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EEGNet_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0fa523bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291108"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "102 * 2854"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b753e1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7191489069348833"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "209350 / 291108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a35eab18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "811c0980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'EEGNet Probabilities')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(4)\n",
    "plt.plot(EEGNet_probs[:,:,1].reshape(-1))\n",
    "plt.plot(task_state.reshape(-1))\n",
    "plt.legend(['EEGNet P(right)', 'Task State (ground truth)'])\n",
    "plt.title(\"EEGNet Probabilities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f41fe807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try thresholding by 0.2 probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbcaf50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholded_preds = np.zeros(EEGNet_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "402e8a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholded_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0b6badb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 1854)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EEGNet_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57718f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholded_preds[:] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6993f65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       ...,\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholded_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43391016",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholded_preds[EEGNet_probs[:,:,1] > 0.8] = 1\n",
    "thresholded_preds[EEGNet_probs[:,:,0] > 0.8] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64627467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "       [0.5, 0.5, 0.5, ..., 0. , 0. , 0. ],\n",
       "       [1. , 0.5, 0.5, ..., 1. , 1. , 1. ],\n",
       "       ...,\n",
       "       [0. , 0. , 0. , ..., 0.5, 0.5, 0.5],\n",
       "       [0. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "       [0.5, 0.5, 1. , ..., 0.5, 0.5, 0.5]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholded_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "758bac9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'EEGNet Thresholded Predicted Outputs')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(thresholded_preds.reshape(-1))\n",
    "plt.plot(task_state.reshape(-1))\n",
    "plt.legend(['EEGNet Prediction', 'Task State (ground truth)'])\n",
    "plt.title(\"EEGNet Thresholded Predicted Outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b0920d",
   "metadata": {},
   "source": [
    "## Draw the decoder based on simulated predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0752c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(189108,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_x = thresholded_preds.reshape(-1)\n",
    "target_x = task_state.reshape(-1)\n",
    "predicted_x.shape\n",
    "target_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b52ead27",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_x = []\n",
    "curr_x_pos = 0.5\n",
    "for ix in range(len(predicted_x)):\n",
    "    if ix %1854 == 0:  # reset decoder position\n",
    "        curr_x_pos = 0.5\n",
    "    if predicted_x[ix] > 0.5:\n",
    "        curr_x_pos += 0.01\n",
    "    elif predicted_x[ix] < 0.5:\n",
    "        curr_x_pos += -0.001\n",
    "    curr_x_pos = np.clip(curr_x_pos, 0, 1)\n",
    "    decoded_x.append(curr_x_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45d1239c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x25b8bdd50b8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(2)\n",
    "plt.plot(predicted_x)\n",
    "plt.plot(target_x)\n",
    "plt.legend([\"predicted\", \"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "81df5c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189108"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "6dfa8b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189108"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "2e29f1ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189108"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(decoded_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fcb93d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x25b8be4ca58>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(3)\n",
    "plt.plot(decoded_x)\n",
    "plt.plot(target_x)\n",
    "plt.legend([\"predicted\", \"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "605cd026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a3ada3a208>]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(task_state.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "28b73a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "eb275f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a3e2a4ef60>]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(predicted_x)\n",
    "plt.plot(predicted_x_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4505de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
